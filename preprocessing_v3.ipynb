{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------  \n",
    "\n",
    "### Preprocessing Video\n",
    "\n",
    "Working on streamlining the preprocessing. Will attempt to pull frame 100 from the entire dataset. Plan is to use cv2 to grab the frame and save the frame to a list. Then use facenet to detect face and crop on face. And then save to disk. \n",
    "\n",
    "<img style=\"float: center;\" src=\"deepfake.jpg\">\n",
    "\n",
    "-------------------------------------------------------------------------------------------------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypi https://pypi.org/project/facenet-pytorch/\n",
    "# !pip3 install facenet-pytorch --user\n",
    "#\n",
    "# install facenet-pytorch on kaggle without internet\n",
    "# !pip install ../facenet-pytorch/facenet_pytorch-2.0.0-py3-none-any.whl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set deepfake directory chunk\n",
    "chunk = 1\n",
    "# frame number to grab from videos\n",
    "frame_num = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = f'/data/deepfake/dfdc_train_part_{chunk}'\n",
    "frame_dir = f'/data/frames/f{frame_num}'\n",
    "meta_file = os.path.join(video_dir, 'metadata.json')\n",
    "\n",
    "os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "with open(meta_file) as f:\n",
    "    metadata = pd.read_json(f).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_frames(sample, frame_num):\n",
    "    video = os.path.join(video_dir, sample)\n",
    "    filename = sample[:-3]+'jpg'\n",
    "    reader = cv2.VideoCapture(video)\n",
    "    reader.set(1, frame_num)\n",
    "    _, image = reader.read()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    images_dict = {}\n",
    "    images_dict[filename] = image\n",
    "    reader.release()\n",
    "    return image, images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=20)(delayed(\n",
    "                   grab_frames)(sample, frame_num)\n",
    "                       for sample in metadata.index)\n",
    "\n",
    "# unpack reults\n",
    "images, results_dict = zip(*results)\n",
    "images = list(images)\n",
    "images_dict = {}\n",
    "for k,v in results_dict.items():\n",
    "    images_dict.update({k:v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(detector, detect_fn, images, *args):\n",
    "    start = time.time()\n",
    "    faces, faces_dict = detect_fn(detector, images, *args)\n",
    "    elapsed = time.time() - start\n",
    "    print(f', {elapsed:.3f} seconds')\n",
    "    return faces, elapsed, faces_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my attempt at adding a dictionary to the for loop to keep track of filenames\n",
    "\n",
    "detector = MTCNN(image_size=224, device=device, post_process=False)\n",
    "\n",
    "\n",
    "def detect_facenet_pytorch(detector, images, batch_size):\n",
    "    faces = []\n",
    "    faces_dict = {}\n",
    "    n = 0\n",
    "    for key in images_dict.keys():\n",
    "    #for lb in np.arange(0, len(images), batch_size):\n",
    "        imgs_pil = [Image.fromarray(images_dict[key])]\n",
    "        #print(type(imgs_pil[0]))\n",
    "        try:\n",
    "            faces.extend(detector(imgs_pil))\n",
    "            #print(len(faces))\n",
    "            faces_dict[key] = faces[n]\n",
    "            n += 1\n",
    "        except:\n",
    "            pass\n",
    "    return faces, faces_dict\n",
    "\n",
    "times_facenet_pytorch_nb = [] # non-batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting faces in frames, 510.758 seconds\n"
     ]
    }
   ],
   "source": [
    "# dtect faces from images\n",
    "print('Detecting faces in frames', end='')\n",
    "faces, elapsed, faces_dict = timer(detector, detect_facenet_pytorch, images, 1)\n",
    "times_facenet_pytorch_nb.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in faces_dict.keys():\n",
    "    try:\n",
    "        image = faces_dict[face].permute(1, 2, 0).int().numpy()\n",
    "        filename = os.path.join(frame_dir, face)\n",
    "        cv2.imwrite(filename, image)\n",
    "    except:\n",
    "        faces_dict[face] = 'no face detected'\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 frames without faces detected\n"
     ]
    }
   ],
   "source": [
    "no_faces_detected = 0\n",
    "for face in faces_dict.keys():\n",
    "    if isinstance(faces_dict[face], str):\n",
    "        no_faces_detected += 1\n",
    "        \n",
    "print(f'{no_faces_detected} frames without faces detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1647"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(frame_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1704"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(video_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
